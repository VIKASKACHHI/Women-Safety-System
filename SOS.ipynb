{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kachh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe hands model\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=4, min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define function to check for a \"fist\" gesture with reduced sensitivity\n",
    "def is_fist(hand_landmarks, threshold=0.05):\n",
    "    for hand_landmark in hand_landmarks:\n",
    "        # Extract landmarks for fingertips (index 8, middle 12, ring 16, pinky 20)\n",
    "        index_tip = hand_landmark.landmark[8]\n",
    "        middle_tip = hand_landmark.landmark[12]\n",
    "        ring_tip = hand_landmark.landmark[16]\n",
    "        pinky_tip = hand_landmark.landmark[20]\n",
    "\n",
    "        # Extract landmarks for knuckles (index 6, middle 10, ring 14, pinky 18)\n",
    "        index_knuckle = hand_landmark.landmark[6]\n",
    "        middle_knuckle = hand_landmark.landmark[10]\n",
    "        ring_knuckle = hand_landmark.landmark[14]\n",
    "        pinky_knuckle = hand_landmark.landmark[18]\n",
    "\n",
    "        # Check if all fingertips are below their corresponding knuckles with a threshold for reduced sensitivity\n",
    "        if (index_tip.y > index_knuckle.y + threshold and\n",
    "            middle_tip.y > middle_knuckle.y + threshold and\n",
    "            ring_tip.y > ring_knuckle.y + threshold and\n",
    "            pinky_tip.y > pinky_knuckle.y + threshold):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Define function to check for a \"cross\" gesture with increased sensitivity\n",
    "def is_cross_sign(hand_landmarks):\n",
    "    if len(hand_landmarks) == 2:\n",
    "        # Extract landmarks for both hands\n",
    "        hand1_landmarks = hand_landmarks[0].landmark\n",
    "        hand2_landmarks = hand_landmarks[1].landmark\n",
    "\n",
    "        # Check if the x-coordinates of specific landmarks indicate crossing\n",
    "        # These landmarks are selected to check crossing\n",
    "        if (abs(hand1_landmarks[8].x - hand2_landmarks[8].x) < 0.1 and  # Compare index finger tips\n",
    "            abs(hand1_landmarks[12].x - hand2_landmarks[12].x) < 0.1):  # Compare middle finger tips\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Start capturing video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Flip the image horizontally for a mirrored view\n",
    "    image = cv2.flip(image, 1)\n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and detect hands\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    # Draw the hand annotations on the image\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Check for specific gestures (fist and cross)\n",
    "        if is_fist(results.multi_hand_landmarks):\n",
    "            # Generate alert for fist gesture\n",
    "            cv2.putText(image, \"Alert: Person is asking for help\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if is_cross_sign(results.multi_hand_landmarks):\n",
    "            # Generate alert for cross sign gesture\n",
    "            cv2.putText(image, \"Alert: Person is asking for help\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow('Hand Gesture Detection', image)\n",
    "\n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
